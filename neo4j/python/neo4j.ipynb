{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j as neo\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'bolt://localhost:7687'\n",
    "auth = ('neo4j', 'neo4j_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_query(tx, query, **args):\n",
    "    \"\"\"\n",
    "    Run one query statement in transaction, and return result\n",
    "    \"\"\"\n",
    "    result = tx.run(query, **args)\n",
    "    return result\n",
    "\n",
    "def _run_transaction(statement_list):\n",
    "    # Make neo4j driver object\n",
    "    driver = neo.GraphDatabase.driver(url, auth=auth)\n",
    "    try:\n",
    "        # Start neo4j session\n",
    "        with driver.session() as session:\n",
    "            results = []\n",
    "            for statement in statement_list:\n",
    "                query = statement['statement']\n",
    "                args = statement.get('args', {})\n",
    "                method = statement.get('method', 'READ')\n",
    "                # Put each statement into transaction\n",
    "                if method == 'WRITE':\n",
    "                    result = session.write_transaction(_run_query, query, **args)\n",
    "                else:\n",
    "                    result = session.read_transaction(_run_query, query, **args)\n",
    "                \n",
    "                results.append(result)\n",
    "                \n",
    "            return results\n",
    "    finally:\n",
    "        driver.close()\n",
    "        \n",
    "def pretty_output(results_lists):\n",
    "    for n in range(0, len(results_lists)):\n",
    "        results = results_lists[n].values()\n",
    "        for m in range(0, len(results)):\n",
    "            for i in range(0, len(results[m])):\n",
    "                print('{}.{}.{}: {}'.format(n, m, i, results[m][i]))\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Node id=2983 labels={'Person'} properties={'gender': 'M', 'name': 'Alvin', 'id': 1}>\n",
      "\n",
      "\n",
      "1.0.0: <Node id=2984 labels={'Person'} properties={'gender': 'F', 'name': 'Emma', 'id': 2}>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create or merge object in neo4j\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MERGE (person:Person {id: {id}, name: {name}, gender: {gender}}) '\n",
    "                     'RETURN person',\n",
    "        'args': {\n",
    "            'id': 1,\n",
    "            'name': 'Alvin',\n",
    "            'gender': 'M' \n",
    "        },\n",
    "        'method': 'WRITE'\n",
    "    },\n",
    "    {\n",
    "        'statement': 'MERGE (person:Person {id: {id}, name: {name}, gender: {gender}}) '\n",
    "                     'RETURN person',\n",
    "        'args': {\n",
    "            'id': 2,\n",
    "            'name': 'Emma',\n",
    "            'gender': 'F' \n",
    "        },\n",
    "        'method': 'WRITE'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Node id=2983 labels={'Person'} properties={'birthday': '1981-03-17', 'name': 'Alvin', 'id': 1, 'gender': 'M'}>\n",
      "\n",
      "\n",
      "1.0.0: <Node id=2984 labels={'Person'} properties={'birthday': '1985-03-29', 'name': 'Emma', 'id': 2, 'gender': 'F'}>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Update exist object\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH (person:Person)'\n",
    "                     'WHERE person.id = {id} '\n",
    "                     'SET person.birthday = {birthday} '\n",
    "                     'RETURN person',\n",
    "        'args': {\n",
    "            'id': 1,\n",
    "            'birthday': '1981-03-17'\n",
    "        },\n",
    "        'method': 'WRITE'\n",
    "    },\n",
    "    {\n",
    "        'statement': 'MATCH (person:Person)'\n",
    "                     'WHERE person.id = {id} '\n",
    "                     'SET person.birthday = {birthday} '\n",
    "                     'RETURN person',\n",
    "        'args': {\n",
    "            'id': 2,\n",
    "            'birthday': '1985-03-29'\n",
    "        },\n",
    "        'method': 'WRITE'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Node id=2983 labels={'Person'} properties={'birthday': '1981-03-17', 'name': 'Alvin', 'id': 1, 'gender': 'M'}>\n",
      "0.0.1: <Node id=2984 labels={'Person'} properties={'birthday': '1985-03-29', 'name': 'Emma', 'id': 2, 'gender': 'F'}>\n",
      "0.0.2: Married\n",
      "\n",
      "\n",
      "1.0.0: <Node id=2983 labels={'Person'} properties={'birthday': '1981-03-17', 'name': 'Alvin', 'id': 1, 'gender': 'M'}>\n",
      "1.0.1: <Node id=2984 labels={'Person'} properties={'birthday': '1985-03-29', 'name': 'Emma', 'id': 2, 'gender': 'F'}>\n",
      "1.0.2: Married\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build relationship\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH (p1:Person), (p2:Person)'\n",
    "                     'WHERE p1.id = {id1} AND p2.id = {id2} '\n",
    "                     'MERGE (p1)-[r:Married]->(p2) '\n",
    "                     'RETURN p1, p2, type(r)',\n",
    "        'args': {\n",
    "            'id1': 1,\n",
    "            'id2': 2\n",
    "        },\n",
    "        'method': 'WRITE'\n",
    "    },\n",
    "    {\n",
    "        'statement': 'MATCH (p1:Person), (p2:Person) '\n",
    "                     'WHERE p1.id = {id1} AND p2.id = {id2} '\n",
    "                     'MERGE (p2)-[r:Married]->(p1) '\n",
    "                     'RETURN p1, p2, type(r)',\n",
    "        'args': {\n",
    "            'id1': 1,\n",
    "            'id2': 2\n",
    "        },\n",
    "        'method': 'WRITE'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Node id=2983 labels={'Person'} properties={'birthday': '1981-03-17', 'name': 'Alvin', 'id': 1, 'gender': 'M'}>\n",
      "0.0.1: <Node id=3567 labels={'Cat'} properties={'name': 'Lily', 'id': 3}>\n",
      "0.0.2: Feed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create object and build relationship\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH (person:Person) '\n",
    "                     'WHERE person.id = {person_id} '\n",
    "                     'MERGE (cat:Cat { id: {cat_id}, name: {cat_name} }) '\n",
    "                     'MERGE (person)-[r:Feed]->(cat) '\n",
    "                     'RETURN person, cat, type(r)',\n",
    "        'args': {\n",
    "            'person_id': 1,\n",
    "            'cat_id': 3,\n",
    "            'cat_name': \"Lily\"\n",
    "        },\n",
    "        'method': 'WRITE'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Node id=2983 labels={'Person'} properties={'birthday': '1981-03-17', 'name': 'Alvin', 'id': 1, 'gender': 'M'}>\n",
      "0.0.1: <Node id=3567 labels={'Cat'} properties={'name': 'Lily', 'id': 3}>\n",
      "0.0.2: Feed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find person who feed cat Lily\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH (person:Person)-[r:Feed]->(cat:Cat) '\n",
    "                     'WHERE cat.name = {cat_name} '\n",
    "                     'RETURN person, cat, type(r)',\n",
    "        'args': {\n",
    "            'cat_name': \"Lily\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: Alvin\n",
      "\n",
      "0.1.0: Emma\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find persons who has relationship with cat Lily\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH (person:Person)-[r*]->(cat:Cat) '\n",
    "                     'WHERE cat.name = {cat_name} '\n",
    "                     'RETURN DISTINCT person.name',\n",
    "        'args': {\n",
    "            'cat_name': 'Lily'\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: Emma\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find who has relationship with cat Lily\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH (p1:Person)-[:Married]-(p2:Person)-[r:Feed*]->(c:Cat) '\n",
    "                     'WHERE c.name={cat_name} '\n",
    "                     'RETURN DISTINCT p1.name',\n",
    "        'args': {\n",
    "            'cat_name': 'Lily'\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Path start=<Node id=2983 labels={'Person'} properties={'birthday': '1981-03-17', 'name': 'Alvin', 'id': 1, 'gender': 'M'}> end=<Node id=3567 labels={'Cat'} properties={'name': 'Lily', 'id': 3}> size=1>\n",
      "0.0.1: 1\n",
      "\n",
      "0.1.0: <Path start=<Node id=2984 labels={'Person'} properties={'birthday': '1985-03-29', 'name': 'Emma', 'id': 2, 'gender': 'F'}> end=<Node id=3567 labels={'Cat'} properties={'name': 'Lily', 'id': 3}> size=2>\n",
      "0.1.1: 2\n",
      "\n",
      "0.2.0: <Path start=<Node id=2983 labels={'Person'} properties={'birthday': '1981-03-17', 'name': 'Alvin', 'id': 1, 'gender': 'M'}> end=<Node id=3567 labels={'Cat'} properties={'name': 'Lily', 'id': 3}> size=3>\n",
      "0.2.1: 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find graph to cat Lily\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH g = (person:Person)-[r*]->(cat:Cat) '\n",
    "                     'WHERE cat.name = {cat_name} '\n",
    "                     'RETURN g, length(g)',\n",
    "        'args': {\n",
    "            'cat_name': 'Lily'\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Node id=3567 labels={'Cat'} properties={'name': 'Lily', 'id': 3}>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find last children node in all relationship\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH ()-[*]->(n:Cat) '\n",
    "                     'WHERE NOT (n)-[]->() '\n",
    "                     'RETURN DISTINCT n'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node physical id is: 3567\n",
      "Node label is: Cat\n",
      "Node property keys are: ['name', 'id']\n",
      "Node property values are: ['Lily', 3]\n",
      "Node property id is: 3\n",
      "Node property name is: Lily\n",
      "--->\n",
      "\tRelationship physical id is: 7932\n",
      "\tRelationship label is: Feed\n",
      "\tRelationship start node id is [id=None, name=None]\n",
      "\tRelationship start node id is [id=3, name=Lily]\n",
      "--->\n",
      "\tRelationship physical id is: 7931\n",
      "\tRelationship label is: Married\n",
      "\tRelationship start node id is [id=None, name=None]\n",
      "\tRelationship start node id is [id=None, name=None]\n",
      "--->\n",
      "\tRelationship physical id is: 8621\n",
      "\tRelationship label is: Married\n",
      "\tRelationship start node id is [id=None, name=None]\n",
      "\tRelationship start node id is [id=None, name=None]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Match results\n",
    "\"\"\"\n",
    "\n",
    "driver = neo.GraphDatabase.driver(url, auth=auth)\n",
    "\n",
    "try:\n",
    "    \n",
    "    def _query_last_node(tx):\n",
    "        return tx.run('MATCH ()-[r*]->(n:Cat) '\n",
    "                      'WHERE NOT (n)-[]->() '\n",
    "                      'RETURN DISTINCT n')\n",
    "\n",
    "    def _print_node(node):\n",
    "        print('Node physical id is: {}'.format(node.id))\n",
    "        print('Node label is: {}'.format(next(iter(node.labels))))\n",
    "        print('Node property keys are: {}'.format(list(node.keys())))\n",
    "        print('Node property values are: {}'.format(list(node.values())))\n",
    "        print('Node property id is: {}'.format(node['id']))\n",
    "        print('Node property name is: {}'.format(node.get('name')))\n",
    "\n",
    "    with driver.session() as session:\n",
    "        result = session.read_transaction(_query_last_node).values() # Get result values\n",
    "        node = result[0][0]\n",
    "        _print_node(node)\n",
    "\n",
    "        \n",
    "    def _print_relationship(relationships):\n",
    "        for r in relationships:\n",
    "            r = r[0][0]\n",
    "            print('--->')\n",
    "            print('\\tRelationship physical id is: {}'.format(r.id))\n",
    "            print('\\tRelationship label is: {}'.format(r.type))\n",
    "            print('\\tRelationship start node id is [id={}, name={}]'.format(\n",
    "                r.start_node['id'], r.start_node['name']))\n",
    "            print('\\tRelationship start node id is [id={}, name={}]'.format(\n",
    "                r.end_node['id'], r.end_node['name']))\n",
    "\n",
    "    def _query_relationship(tx):\n",
    "        return tx.run('MATCH ()-[r*]->(n:Cat) '\n",
    "                      'WHERE NOT (n)-[]->() '\n",
    "                      'RETURN DISTINCT r, n')\n",
    "\n",
    "    with driver.session() as session:\n",
    "        result = session.read_transaction(_query_relationship).values() # Get result values\n",
    "        _print_relationship(result)\n",
    "        \n",
    "finally:\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Relationship id=8621 nodes=(<Node id=2983 labels=set() properties={}>, <Node id=2984 labels=set() properties={}>) type='Married' properties={}>\n",
      "0.0.1: <Relationship id=7932 nodes=(<Node id=2983 labels=set() properties={}>, <Node id=3567 labels=set() properties={}>) type='Feed' properties={}>\n",
      "0.0.2: <Node id=2983 labels=set() properties={}>\n",
      "0.0.3: <Node id=3567 labels=set() properties={}>\n",
      "\n",
      "0.1.0: <Relationship id=8621 nodes=(<Node id=2983 labels=set() properties={}>, <Node id=2984 labels=set() properties={}>) type='Married' properties={}>\n",
      "0.1.1: <Relationship id=7932 nodes=(<Node id=2983 labels=set() properties={}>, <Node id=3567 labels=set() properties={}>) type='Feed' properties={}>\n",
      "0.1.2: <Node id=2984 labels=set() properties={}>\n",
      "0.1.3: <Node id=3567 labels=set() properties={}>\n",
      "\n",
      "0.2.0: <Relationship id=7931 nodes=(<Node id=2984 labels=set() properties={}>, <Node id=2983 labels=set() properties={}>) type='Married' properties={}>\n",
      "0.2.1: <Relationship id=7932 nodes=(<Node id=2983 labels=set() properties={}>, <Node id=3567 labels=set() properties={}>) type='Feed' properties={}>\n",
      "0.2.2: <Node id=2983 labels=set() properties={}>\n",
      "0.2.3: <Node id=3567 labels=set() properties={}>\n",
      "\n",
      "0.3.0: <Relationship id=7931 nodes=(<Node id=2984 labels=set() properties={}>, <Node id=2983 labels=set() properties={}>) type='Married' properties={}>\n",
      "0.3.1: <Relationship id=7932 nodes=(<Node id=2983 labels=set() properties={}>, <Node id=3567 labels=set() properties={}>) type='Feed' properties={}>\n",
      "0.3.2: <Node id=2984 labels=set() properties={}>\n",
      "0.3.3: <Node id=3567 labels=set() properties={}>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Delete nodes with relationships\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'MATCH ()-[mr:Married]->() '\n",
    "                     'MATCH ()-[fr:Feed]->() '\n",
    "                     'OPTIONAL MATCH (ps:Person) '\n",
    "                     'OPTIONAL MATCH(cs:Cat) '\n",
    "                     'DELETE mr, fr, ps, cs '\n",
    "                     'RETURN mr, fr, ps, cs'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Node id=3568 labels={'Person'} properties={'name': 'Alvin', 'id': '1'}>\n",
      "0.0.1: <Node id=3569 labels={'Person'} properties={'name': 'Emma', 'id': '2'}>\n",
      "\n",
      "0.1.0: <Node id=3569 labels={'Person'} properties={'name': 'Emma', 'id': '2'}>\n",
      "0.1.1: <Node id=3568 labels={'Person'} properties={'name': 'Alvin', 'id': '1'}>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import from csv\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'LOAD CSV WITH HEADERS FROM \"file:///data.csv\" AS line '\n",
    "                     'MERGE (p1:Person {id: line[\"id\"], name: line[\"name\"]}) '\n",
    "                     'MERGE (p2:Person {id: line[\"married\"]}) '\n",
    "                     'MERGE (p1)-[:Married]->(p2) '\n",
    "                     'RETURN p1, p2'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: lithuanian\n",
      "0.0.1: Lithuanian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.1.0: simple\n",
      "0.1.1: A simple analyzer that tokenizes at non-letter boundaries. No stemming or filtering. Works okay for most European languages, but is terrible for languages where words are not separated by spaces, such as many Asian languages.\n",
      "\n",
      "0.2.0: latvian\n",
      "0.2.1: Latvian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.3.0: cjk\n",
      "0.3.1: CJK - Chinese/Japanese/Korean - analyzer. Terms are normalised and case-folded. Produces bi-grams, and filters out stop words.\n",
      "\n",
      "0.4.0: sorani\n",
      "0.4.1: Sorani Kurdish analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.5.0: stop\n",
      "0.5.1: Stop analyzer tokenizes at non-letter characters, and filters out English stop words. This differs from the 'classic' and 'standard' analyzers in that it makes no effort to recognize special terms, like likely product names, URLs or email addresses.\n",
      "\n",
      "0.6.0: indonesian\n",
      "0.6.1: Indonesian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.7.0: keyword\n",
      "0.7.1: Keyword analyzer \"tokenizes\" the text as a single term. Useful for zip-codes, ids, etc. Situations where complete and exact matches are desired.\n",
      "\n",
      "0.8.0: arabic\n",
      "0.8.1: Arabic analyzer with light stemming, as specified by \"Light Stemming for Arabic Information Retrieval\".\n",
      "\n",
      "0.9.0: standard\n",
      "0.9.1: The default, standard analyzer. Tokenizes on non-letter and filters out English stop words and punctuation. Does no stemming, but takes care to keep likely product names, URLs and email addresses as single terms.\n",
      "\n",
      "0.10.0: galician\n",
      "0.10.1: Galician analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.11.0: german\n",
      "0.11.1: German analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.12.0: unicode_whitespace\n",
      "0.12.1: Breaks text into terms by characters that have the unicode WHITESPACE property.\n",
      "\n",
      "0.13.0: bulgarian\n",
      "0.13.1: Bulgarian analyzer with light stemming, as specified by \"Searching Strategies for the Bulgarian Language\", and stop word filtering.\n",
      "\n",
      "0.14.0: brazilian\n",
      "0.14.1: Brazilian Portuguese analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.15.0: basque\n",
      "0.15.1: Basque analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.16.0: english\n",
      "0.16.1: English analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.17.0: irish\n",
      "0.17.1: Irish analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.18.0: portuguese\n",
      "0.18.1: Portuguese analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.19.0: url_or_email\n",
      "0.19.1: Tokenizes into sequences of alpha-numeric, numeric, URL, email, southeast asian terms, and into terms of individual ideographic and hiragana characters. English stop words are filtered out.\n",
      "\n",
      "0.20.0: url\n",
      "0.20.1: Tokenizes into sequences of alpha-numeric, numeric, URL, email, southeast asian terms, and into terms of individual ideographic and hiragana characters. English stop words are filtered out.\n",
      "\n",
      "0.21.0: email\n",
      "0.21.1: Tokenizes into sequences of alpha-numeric, numeric, URL, email, southeast asian terms, and into terms of individual ideographic and hiragana characters. English stop words are filtered out.\n",
      "\n",
      "0.22.0: finnish\n",
      "0.22.1: Finnish analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.23.0: hindi\n",
      "0.23.1: Hindi analyzer with stemming, normalization, and stop word filtering.\n",
      "\n",
      "0.24.0: catalan\n",
      "0.24.1: Catalan analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.25.0: danish\n",
      "0.25.1: Danish analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.26.0: norwegian\n",
      "0.26.1: Norwegian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.27.0: russian\n",
      "0.27.1: Russian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.28.0: thai\n",
      "0.28.1: Thai analyzer with stop word filtering. It relies on the Java built-in localization support for the Thai locale in order to break apart and tokenize words, which might not be available depending on Java version and JRE vendor.\n",
      "\n",
      "0.29.0: dutch\n",
      "0.29.1: Dutch analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.30.0: spanish\n",
      "0.30.1: Spanish analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.31.0: swedish\n",
      "0.31.1: Swedish analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.32.0: armenian\n",
      "0.32.1: Armenian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.33.0: greek\n",
      "0.33.1: Greek analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.34.0: romanian\n",
      "0.34.1: Romanian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.35.0: hungarian\n",
      "0.35.1: Hungarian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.36.0: classic\n",
      "0.36.1: Classic Lucene analyzer. Similar to 'standard', but with worse unicode support.\n",
      "\n",
      "0.37.0: turkish\n",
      "0.37.1: Turkish analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.38.0: italian\n",
      "0.38.1: Italian analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.39.0: czech\n",
      "0.39.1: Czech analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.40.0: french\n",
      "0.40.1: French analyzer with stemming and stop word filtering.\n",
      "\n",
      "0.41.0: whitespace\n",
      "0.41.1: Breaks text into terms by characters that are considered \"Java whitespace\".\n",
      "\n",
      "0.42.0: persian\n",
      "0.42.1: Persian analyzer. Tokenizes with zero-width non-joiner characters in addition to whitespace. Persian-specific variants, such as the farsi 'yeh' and 'keheh', are standardized. Simple stemming is accomplished via stop words.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "List all lucence fulltext search analyzers\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'CALL db.index.fulltext.listAvailableAnalyzers()'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create fulltext index\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'CALL db.index.fulltext.createNodeIndex(\"ix_name\", [\"Person\", \"Cat\"], [\"name\"], {analyzer: \"cjk\"})'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.0: <Node id=3568 labels={'Person'} properties={'name': 'Alvin', 'id': '1'}>\n",
      "0.0.1: 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Query by fulltext index\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'CALL db.index.fulltext.queryNodes(\"ix_name\", \"Alvin\") YIELD node, score '\n",
    "                     'RETURN node, score'\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Query by fulltext index\n",
    "\"\"\"\n",
    "\n",
    "statements = [\n",
    "    {\n",
    "        'statement': 'CALL db.index.fulltext.drop(\"ix_name\") '\n",
    "    }\n",
    "]\n",
    "\n",
    "pretty_output(_run_transaction(statements))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
